import os
import queue
import threading
import time
import pyaudio
import random
from google.cloud import speech
import google.generativeai as genai
import signal
import sys
import json
import io
import socketio

# åˆå§‹åŒ– Socket.io
sio = socketio.Client()
sio.connect("http://localhost:5000")

# å‚³é€è³‡æ–™çµ¦å‰ç«¯
def send_to_server(json_data):
    sio.emit('feedback', json_data)

# ä¿®æ­£è¼¸å‡ºç·¨ç¢¼
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)

# é‡‘é‘°èˆ‡åƒæ•¸è¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.join(BASE_DIR, "dark-bindery-460212-q0-bee5668840a0.json")
genai.configure(api_key="AIzaSyCraB2L_7kSW9iSX5t-Hi8IXG6-cXAuUqE")

RATE = 16000
CHUNK = int(RATE / 10)  # 1600

# åˆå§‹åŒ– Gemini æ¨¡å‹
gemini_model = genai.GenerativeModel("gemini-1.5-pro")

# å»ºç«‹è§€çœ¾è§’è‰²
def create_chat_session(prompt):
    return gemini_model.start_chat(history=[
        {"role": "user", "parts": [prompt]},
        {"role": "model", "parts": ["äº†è§£ ç¾åœ¨é–‹å§‹é€²å…¥è§’è‰²æ¨¡å¼å›‰ ç°¡çŸ­å›å¾© å£èªåŒ– ä¸è¦é¡¯ç¤ºå¿ƒè² ä¸è¦è¡¨ç¾åƒAI ä¸è¦æœ‰è¡¨æƒ…ç¬¦è™Ÿ ä¸è¦æœ‰()ç¬¦è™Ÿå‡ºç¾åœ¨å›æ‡‰ ä¸è¦è¶…éäºŒåå€‹å­—"]}
    ])

audience_profiles = {
    "çµ±ç¥": {"session": create_chat_session("ä½ æ˜¯é˜¿æ»´è‹±æ–‡çš„è§€çœ¾ï¼Œå«ä»–æ’­æ’­"), "engagement_level": 1.0},
    "ç¾…å‚‘è§€çœ¾": {"session": create_chat_session("ä½ æ˜¯ç¾…å‚‘ç›´æ’­è§€çœ¾ï¼Œå«ä»–æ’­æ’­"), "engagement_level": 1.0},
    "Toyz": {"session": create_chat_session("ä½ æ˜¯Toyzè§€çœ¾ï¼Œå«ä»–ä¸»æ’­"), "engagement_level": 1.0},
    "æ„›è‰èè": {"session": create_chat_session("ä½ æ˜¯æ„›è‰èèçš„è§€çœ¾"), "engagement_level": 1.0},
    "å°æ—¥åˆ€å£": {"session": create_chat_session("ä½ æ˜¯å°æ—¥åˆ€å£çš„è§€çœ¾ï¼Œå«ä»–åª½æ–¯å¡”"), "engagement_level": 1.0},
    "åœ‹å‹•": {"session": create_chat_session("ä½ æ˜¯åœ‹å‹•çš„è§€çœ¾ï¼Œå«ä»–å¸¥å‹¾"), "engagement_level": 1.0},
    "è©©äºº": {"session": create_chat_session("ä½ æ˜¯å€‹å¥½å¥‡å¿ƒå¼·çš„è©©äººå‹è§€çœ¾"), "engagement_level": 1.0},
    "ç¾…å‚‘": {"session": create_chat_session("ä½ æ˜¯å”å’–å‹ç¾…å‚‘è§€çœ¾ï¼Œå«ä»–æ’­æ’­"), "engagement_level": 1.0}
}

# å• Gemini å¾—åˆ°è§€çœ¾å›æ‡‰
def ask_gemini(message):
    replies = []
    for name, profile in audience_profiles.items():
        if random.random() < profile["engagement_level"]:
            try:
                reply = profile["session"].send_message(message).text
                replies.append(f"[{name}]: {reply}")
            except Exception as e:
                replies.append(f"[{name}]: âš ï¸ å›æ‡‰å¤±æ•—ï¼š{e}")
    return "\n".join(replies) if replies else ""

# éº¥å…‹é¢¨ä¸²æµ
class MicrophoneStream:
    def __init__(self, rate, chunk):
        self.rate = rate
        self.chunk = chunk
        self.closed = True
        self._buff = queue.Queue()
        self._audio_interface = pyaudio.PyAudio()

    def __enter__(self):
        self._stream = self._audio_interface.open(
            format=pyaudio.paInt16,
            channels=1,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk,
            stream_callback=self._callback,
        )
        self.closed = False
        return self

    def __exit__(self, type, value, traceback):
        self._stream.stop_stream()
        self._stream.close()
        self._audio_interface.terminate()
        self.closed = True

    def _callback(self, in_data, frame_count, time_info, status_flags):
        self._buff.put(in_data)
        return None, pyaudio.paContinue

    def generator(self):
        while not self.closed:
            data = self._buff.get()
            if data is None:
                return
            yield data

# èªéŸ³è¾¨è­˜ä¸»é‚è¼¯
def listen_print_loop(responses):
    last_transcript = ""
    speech_end_timer = None
    IDLE_SECONDS = 10
    SPEECH_GAP = 0.8

    def lower_engagement_all():
        for p in audience_profiles.values():
            p["engagement_level"] = max(0.2, p["engagement_level"] - 0.2)

    def reset_engagement_all():
        for p in audience_profiles.values():
            p["engagement_level"] = 1.0

    def on_speech_end():
        nonlocal last_transcript
        if last_transcript.strip() != "":
            print(f"\n[speech end] è¾¨è­˜å®Œæˆï¼š{last_transcript}")
            reply = ask_gemini(last_transcript)
            result_data = {
                "type": "response",
                "transcript": last_transcript,
                "aiReplies": reply.split("\n")
            }
            print(json.dumps(result_data, ensure_ascii=False), flush=True)
            send_to_server(result_data)
            if len(last_transcript) > 8:
                reset_engagement_all()
            last_transcript = ""

    def reset_speech_end_timer():
        nonlocal speech_end_timer
        if speech_end_timer:
            speech_end_timer.cancel()
        speech_end_timer = threading.Timer(SPEECH_GAP, on_speech_end)
        speech_end_timer.start()

    def on_idle():
        print("[idle] 10ç§’å…§ç„¡èªéŸ³è¼¸å…¥ è‡ªå‹•è§¸ç™¼è§€çœ¾å›æ‡‰")
        lower_engagement_all()
        reply = ask_gemini("......")
        result_data = {
            "type": "response",
            "transcript": "......",
            "aiReplies": reply.split("\n")
        }
        print(json.dumps(result_data, ensure_ascii=False), flush=True)
        send_to_server(result_data)

    def reset_idle_timer():
        global idle_timer
        if idle_timer:
            idle_timer.cancel()
        idle_timer = threading.Timer(IDLE_SECONDS, on_idle)
        idle_timer.start()

    print("[listen] é–‹å§‹æ¥æ”¶è¾¨è­˜çµæœ")
    try:
        for response in responses:
            if not response.results:
                continue
            result = response.results[0]
            transcript = result.alternatives[0].transcript.strip()
            if transcript != "":
                last_transcript = transcript
                reset_speech_end_timer()
                reset_idle_timer()

            if result.is_final:
                print(f"[final] {transcript}")

        if idle_timer:
            idle_timer.cancel()
        if speech_end_timer:
            speech_end_timer.cancel()

    except Exception as e:
        print(f"\n[listen] éŒ¯èª¤ï¼š{e}")

# æ§åˆ¶æ˜¯å¦ç¹¼çºŒåŸ·è¡Œçš„æ——æ¨™
running = True

# SIGTERM çµæŸè¨Šè™Ÿè™•ç†
def signal_handler(sig, frame):
    global running
    print('[feedback.py] æ”¶åˆ° SIGTERMï¼Œæ­£åœ¨çµæŸ')
    running = False

signal.signal(signal.SIGTERM, signal_handler)

# ä¸»è¾¨è­˜æµç¨‹
def main():
    client = speech.SpeechClient()

    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=RATE,
        language_code="zh-TW",
    )

    streaming_config = speech.StreamingRecognitionConfig(
        config=config,
        interim_results=True
    )

    with MicrophoneStream(RATE, CHUNK) as stream:
        audio_generator = stream.generator()
        request_queue = queue.Queue()

        def fill_queue():
            for content in audio_generator:
                request_queue.put(speech.StreamingRecognizeRequest(audio_content=content))

        def request_generator():
            while running:
                chunk = request_queue.get()
                if chunk is None:
                    break
                yield chunk

        threading.Thread(target=fill_queue, daemon=True).start()

        try:
            responses = client.streaming_recognize(streaming_config, request_generator())
            listen_print_loop(responses)
        except Exception as e:
            print(f"[main] API éŒ¯èª¤ï¼š{e}")

# ä¸»è¿´åœˆ
if __name__ == "__main__":
    while running:
        main()
        print("ğŸ”„ é‡å•Ÿè¾¨è­˜ä¸²æµä¸­...\n")
        time.sleep(1)

    sio.disconnect()
    print("âœ… å·²ä¸­æ­¢è¾¨è­˜ä¸¦é—œé–‰ socket.io")
